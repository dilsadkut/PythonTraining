# -*- coding: utf-8 -*-
"""Pandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D7TopFIwy6vVOOz8Hb3Y65O-lJyfpvfS

# Pandas
"""

import pandas as pd

#first column is index 
#second column value
pd.Series([10,88,3,4,5])

seri = pd.Series([10,88,3,4,5])
type(seri)

#The index structure of the series is accessed.
seri.axes

seri.ndim

seri.dtype

seri.size

seri.values

#return the first 5 row
seri.head()

seri.head(3)

#return the last 5 row
seri.tail(3)

seri1 = pd.Series([99,23,76,2323,98], index = [1,3,5,7,9])
seri1

seri2 = pd.Series([99,23,76,2323,98], index = ["a","b","c","d","e"])
seri2

seri2["a"]

seri2["a":"c"]

#Create a dictinary
dic1 = {"reg":10, "log":11,"cart":12}

series = pd.Series(dic1)

series

#concatenation
pd.concat([series,series])

"""# Indexing and Slicing"""

import numpy as np
a = np.array([1,2,33,444,75], dtype = "int64")
seri = pd.Series(a)
seri

seri[0]

#slicing
seri[0:3]

seri = pd.Series([121,200,150,99], index = ["reg","loj","cart","rf"])
seri

#this method just uses to access indexes.
seri.index

#this method just uses to access keys.
seri.keys

#it can be used like dictionary method.
list(seri.items())

seri.values

"reg" in seri

"a" in seri

seri["reg"]

#fancy 
seri[["rf","reg"]]

seri["reg"] = 130
seri["reg"]

seri["reg":"loj"]

seri["reg"] in seri

"reg" in seri

130 in seri.items()

"""
# Creating DataFrame """

#NumPy cannot keep categorical and numeric data together. That's why we need a Pandas.
import pandas as pd
l = [1,2,23,345,7,8,3]
l

pd.DataFrame(l,columns = ["degisken_isimleri"])

import numpy as np
m = np.arange(1,10).reshape((3,3))
m

pd.DataFrame(m, columns=["var1","var2","var3"])

#dataframe renaming
df =pd.DataFrame(m, columns=["var1","var2","var3"])
df.head()

df.columns

df.columns = ["deg1","deg2","deg3"]

df

df.index

df

df.describe()

df.T

type(df)

df.axes

df.shape

df.ndim

df.size

df.values

type(df.values)

df.head()

df.tail(1)

a = np.array([1,2,3,4,5])
pd.DataFrame(a, columns =["deg1"])

import numpy as np
s1 = np.random.randint(10,size = 5)
s2 = np.random.randint(10,size = 5)
s3 = np.random.randint(10,size = 5)

dic1 = {"var1":s1, "var2":s2, "var3":s3}
dic1

df = pd.DataFrame(dic1)
df

df[0:1]

df[0:2]

df.index = ["a","b","c","d","e"]
df

df["c":"e"]

df.drop("a", axis = 0)

df

#inplace = If we make it true, the drop will be done permanently.
df.drop("a", axis = 0, inplace = True)

df

#fancy
l = {"c","e"}
df.drop(l, axis = 0)

"var1" in df

l = ["var1","var4","var2"]
for i in l:
    print(i in df)

l = ["var1","var2"]
df.drop(l, axis = 1)

"""# loc & iloc"""

import numpy as np
import pandas as pd
m = np.random.randint(1,30, size = (10,3))
df = pd.DataFrame(m, columns=["var1","var2","var3"])
df

df.loc[0:3]

df.iloc[0:3]

df.iloc[0,0]

df.iloc[:3,:2]

df.loc[0:3,"var3"]

df.iloc[0:3]["var3"]

df[0:2]

df.iloc[0:2]

df.loc[0:2]

df.iloc[:,:2]

df.iloc[:,0]

df.loc[0:3,"var3"]

df.iloc[0:3]["var3"]

"""# Conditional Operations"""

df[0:2][["var1","var2"]]

df.var1 > 15

df[df.var1 > 15]["var2"]

df[(df.var1 >10) & (df.var3 < 8)]

df.loc[(df.var1 >10),["var1","var2"]]

df[(df.var1 >10)][["var1","var2"]]

"""# Join"""

import numpy as np
import pandas as pd
m = np.random.randint(1,30, size = (10,3))
df1 = pd.DataFrame(m, columns=["var1","var2","var3"])
df1

df2 = df1 + 99
df2

pd.concat([df1,df2])

pd.concat([df1,df2], ignore_index=True)

df1.columns

df2.columns = ["var1","var2","deg3"]
df2

df1

df2

pd.concat([df1,df2])

pd.concat([df1,df2], join="inner", ignore_index=True)

?pd.concat

pd.concat([df1,df2], join_axes = [df2.columns], ignore_index= True)

df1.columns

df2.columns

"""# Concatenation"""

import pandas as pd

df1 = pd.DataFrame({'Worker':['John','Doe','Mehmet','Jeff'],
                    'Positions':['HR','Engineering','AI','Accounting']
                   })
df1

df2 = pd.DataFrame({'Worker':['John','Doe','Mehmet','Jeff'],
                   
                    'Date_Of_starting_work':[2012,'2018','2015','2017']
                   })
df2

pd.merge(df1,df2)

#many to one
df3 = pd.merge(df1,df2, on = "Worker")
df3

df4 = pd.DataFrame({'Positions':['Accounting',"Engineering",'HR'],
                    'Mudur': ['Caner','Mustafa','Berkcan']
                   })
pd.merge(df3,df4)

pd.merge(df3,df4)

#many to many
df5 = pd.DataFrame({'Positions':['Accounting','Accounting',"Engineering","Engineering",'HR','HR'],
                    'Ability': ['Math','Excel','Coding','Linux','Excel','Management']
                   })
    
df5

df1

pd.merge(df1,df5)

"""# Aggregation & Grouping

* count()
* first()
* last()
* mean()
* median()
* min()
* max()
* std()
* var()
* sum()
"""

#seaborn has a lot of dataset in own itself.
import seaborn as sns

?sns.load_dataset

df = sns.load_dataset("planets")
df

df.head()

df.shape

df.mean()

df["mass"]

df['mass'].mean()

import numpy as np

a = df["mass"].mean()
print(a.astype("int32").dtype)
a

df["mass"].count()

df["mass"].min()

df["mass"].max()

df["mass"].sum()

df["mass"].std()

#variance
df["mass"].var()

df.describe()

df.describe().T

#missing value
df.dropna().describe().T

"""# GroupBy"""

df = pd.DataFrame({'gruplar': ['A','B','C','A','B','C'],
                   'veri': [10,11,52,23,43,55]}, columns = ['gruplar','veri'])
df

df.groupby("gruplar")

df.groupby("gruplar").mean()

df.groupby("gruplar").sum()

df = sns.load_dataset("planets")
df.head()

df.groupby("method").count()

df.groupby("method")["orbital_period"].mean()

df.groupby("method")["mass"].mean()

df.groupby("method")["orbital_period"].describe()

"""# Aggregation"""

import numpy as np
import pandas as pd
import seaborn as sns

df = pd.DataFrame({'gruplar': ['A','B','C','A','B','C'],
                   'değişken1': [10,23,33,22,11,99],
                   'değişken2':[100,253,333,262,111,969]},
                  columns = ['gruplar','değişken1','değişken2'])
df

# aggregate

df.groupby('gruplar').mean()

df.groupby('gruplar').aggregate([min, np.median, max])

df.groupby('gruplar').aggregate({"değişken1":"min","değişken2": "max"})

"""### filter """

import numpy as np
import pandas as pd
import seaborn as sns

df = pd.DataFrame({'gruplar': ['A','B','C','A','B','C'],
                   'değişken1': [10,23,33,22,11,99],
                   'değişken2':[100,253,333,262,111,969]},
                  columns = ['gruplar','değişken1','değişken2'])
df

def filter_func(x):
    return x["değişken1"].std() > 9

df.groupby("gruplar").std()

df.groupby("gruplar").filter(filter_func)

"""### Transform"""

import numpy as np
import pandas as pd
import seaborn as sns

df = pd.DataFrame({'gruplar': ['A','B','C','A','B','C'],
                   'değişken1': [10,23,33,22,11,99],
                   'değişken2':[100,253,333,262,111,969]},
                  columns = ['gruplar','değişken1','değişken2'])
df

df["değişken1"] * 9

df_a = df.iloc[:,1:3]
df_a

df_a.transform(lambda x : x - x.mean())

df_a.transform(lambda x : (x - x.mean()) / x.std())

"""### Apply"""

import numpy as np
import pandas as pd
import seaborn as sns

df1 = pd.DataFrame({'gruplar': ['A','B','C','A','B','C'],
                   'değişken1': [10,23,33,22,11,99],
                   'değişken2':[100,253,333,262,111,969]},
                  columns = ['gruplar','değişken1','değişken2'])
df1

df1.apply(np.sum)

df1.apply(np.mean)

df1.groupby("gruplar").apply(np.sum)

df1.groupby("gruplar").apply(np.mean)

"""# Pivot Tablolar"""

import pandas as pd
import seaborn as sns
titanic = sns.load_dataset('titanic')
titanic.head()

titanic.groupby("sex")["survived"].mean()

titanic.groupby("sex")[["survived"]].mean()

titanic.groupby(["sex","class"])[["survived"]].aggregate("mean").unstack()

titanic.groupby(["sex","class"])[["survived"]].aggregate("mean")

titanic.pivot_table("survived", index = "sex", columns = "class")

titanic.age.head(10)

age = pd.cut(titanic["age"], [0,18,23])
age.head(10)

titanic.pivot_table("survived", ["sex",age], "class")

#read csv
import pandas as pd
pd.read_csv("ornekcsv.csv", sep = ";" )

#read txt
pd.read_csv("duz_metin.txt")

#read excel
pd.read_excel("ornekx.xlsx")
pd

#txt okuma 
tips = pd.read_csv("data.txt")
tips

